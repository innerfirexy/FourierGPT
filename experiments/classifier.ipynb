{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features(spec_file: str, interp_len: int = 500):\n",
    "    df = pd.read_csv(spec_file)\n",
    "\n",
    "    # `sid` column does not exist\n",
    "    if 'sid' not in df.columns:\n",
    "        df['sdiff']  = df['freq'] < df['freq'].shift(1, fill_value=0)\n",
    "        df['sdiff'] = df['sdiff'].astype(int)\n",
    "        df['sid'] = df['sdiff'].cumsum()\n",
    "\n",
    "    features_interp = []\n",
    "    for sid, group in df.groupby('sid'):\n",
    "        freqs = group['freq'].values\n",
    "        features = group['power'].values\n",
    "        new_freq = np.linspace(0, 0.5, interp_len)\n",
    "        new_feat = np.interp(new_freq, freqs, features)\n",
    "        features_interp.append(new_feat)\n",
    "\n",
    "    return np.array(features_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gpt4_orig = get_features('../data/gpt-4/pubmed_gpt-4.original.mistral.fftnorm.txt')\n",
    "y_gpt4_orig = np.zeros(x_gpt4_orig.shape[0])\n",
    "# print(x_gpt4_orig.shape, y_gpt4_orig.shape)\n",
    "\n",
    "x_gpt4_samp = get_features('../data/gpt-4/pubmed_gpt-4.sampled.mistral.fftnorm.txt')\n",
    "y_gpt4_samp = np.ones(x_gpt4_samp.shape[0])\n",
    "# print(x_gpt4_samp.shape, y_gpt4_samp.shape)\n",
    "\n",
    "feature_ratio = 0.15\n",
    "x_gpt4_orig = x_gpt4_orig[:, :int(feature_ratio * x_gpt4_orig.shape[1])]\n",
    "x_gpt4_samp = x_gpt4_samp[:, :int(feature_ratio * x_gpt4_samp.shape[1])]\n",
    "\n",
    "x_gpt4 = np.concatenate([x_gpt4_orig, x_gpt4_samp], axis=0)\n",
    "y_gpt4 = np.concatenate([y_gpt4_orig, y_gpt4_samp], axis=0)\n",
    "\n",
    "print(x_gpt4.shape, y_gpt4.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x_gpt4, y_gpt4, test_size=0.2, random_state=42)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(\n",
    "#     x_davinci, y_davinci, test_size=0.2, random_state=42)\n",
    "\n",
    "print('train:', x_train.shape, y_train.shape)\n",
    "print('test:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "model.fit(x_train, y_train)\n",
    "y_pred = model.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(accuracy)\n",
    "\n",
    "scores = cross_val_score(model, x_gpt4, y_gpt4, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "# Using the lower 15% of spectral features, the SVM model achieved an accuracy of 0.75 on the GPT-4 dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use FACE-SO style method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_SO(data, ref):\n",
    "    \"\"\"\n",
    "    Compute the overlap between data and ref\n",
    "    \"\"\"\n",
    "    data_abs = np.abs(data)\n",
    "    ref_abs = np.abs(ref)\n",
    "    intersect = np.amin([data_abs, ref_abs], axis=0)\n",
    "    roof = np.amax([data_abs, ref_abs], axis=0)\n",
    "    area_intersect = np.trapz(intersect)\n",
    "    area_roof = np.trapz(roof)\n",
    "    return area_intersect / area_roof\n",
    "\n",
    "def compute_SO2(data, ref):\n",
    "    \"\"\"\n",
    "    Compute the overlap between data and ref; using np.sum\n",
    "    \"\"\"\n",
    "    data_abs = np.abs(data)\n",
    "    ref_abs = np.abs(ref)\n",
    "    intersect = np.amin([data_abs, ref_abs], axis=0)\n",
    "    roof = np.amax([data_abs, ref_abs], axis=0)\n",
    "    area_intersect = np.sum(intersect)\n",
    "    area_roof = np.sum(roof)\n",
    "    return area_intersect / area_roof\n",
    "\n",
    "#todo: Test SO function from FACE-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test SO functions\n",
    "data = np.array(range(0,5))\n",
    "ref = np.array(range(4,-1,-1))\n",
    "\n",
    "# plot \n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(data, )\n",
    "plt.scatter(range(5), data)\n",
    "plt.plot(ref, )\n",
    "plt.scatter(range(5), ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "so1 = compute_SO(data, ref)\n",
    "print(so1)\n",
    "so2 = compute_SO2(data, ref)\n",
    "print(so2)\n",
    "\n",
    "# correct answer is 0.3333"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try mean value distance as a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_cl_boot(fft.gpt4.orig[freq < 0.5*lower_ratio, power])\n",
    "#           y     ymin   ymax\n",
    "#  1 3.264593 2.917913 3.6123\n",
    "# mean_cl_boot(fft.gpt4.samp[freq < 0.5*lower_ratio, power])\n",
    "#           y     ymin     ymax\n",
    "#  1 4.503291 4.084666 4.976448\n",
    "\n",
    "pow_max_orig = 3.6123\n",
    "pow_mean_orig = 3.264593\n",
    "pow_min_samp = 4.084666\n",
    "pow_mean_samp = 4.503291\n",
    "\n",
    "def mean_val_cls(x, y, pow_orig, pow_samp, left_end, right_end):\n",
    "    \"\"\"\n",
    "    x: interpolated spectra\n",
    "    y: 0 for original (human), 1 for sampled (model)\n",
    "    left_end: left end of the frequency range, [0, 0.5]\n",
    "    right_end: right end of the frequency range, [0, 0.5]\n",
    "    \"\"\"\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    max_freq = 0.5\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    for i in range(x.shape[0]):\n",
    "        mean_x = np.mean(x[i, int(left_end/max_freq * x.shape[1]): int(right_end/max_freq * x.shape[1])])\n",
    "        current_y = y[i] # 0 for orig, 1 for samp\n",
    "        if current_y == 0:\n",
    "            if np.abs(mean_x - pow_orig) <= np.abs(mean_x - pow_samp): # closer to orig\n",
    "                tn += 1\n",
    "            else: # closer to samp\n",
    "                fp += 1\n",
    "        else:\n",
    "            if np.abs(mean_x - pow_orig) <= np.abs(mean_x - pow_samp): # closer to orig\n",
    "                fn += 1\n",
    "            else: # closer to samp\n",
    "                tp += 1\n",
    "    return tp, tn, fp, fn\n",
    "\n",
    "def print_scores(tp, tn, fp, fn):\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "    print('acc:', acc)\n",
    "    print('precision:', precision)\n",
    "    print('recall:', recall)\n",
    "    print('f1:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use pow_max_orig, pow_min_samp\n",
    "tp, tn, fp, fn = mean_val_cls(x_gpt4, y_gpt4, pow_max_orig, pow_min_samp, left_end=0.075, right_end=0.5)\n",
    "print_scores(tp, tn, fp, fn)\n",
    "\n",
    "## Best perf so far, better than SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp, tn, fp, fn = mean_val_cls(x_gpt4, y_gpt4, pow_max_orig, pow_min_samp, lower_ration=0.08)\n",
    "print_scores(tp, tn, fp, fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLL log zscore \n",
    "# x_orig = get_features('../data/gpt-4/pubmed_Ans_gpt-4.original.gpt2.nlllogzs.fftreal.txt')\n",
    "# x_orig = get_features('../data/gpt-4/pubmed_Ans_gpt-4.original.gpt2xl.nlllogzs.fftreal.txt')\n",
    "x_orig = get_features('../data/gpt-4/pubmed_QA_gpt-4.original.gpt2xl.nlllogzs.fftnorm.circlemean.txt') # Best acc=.80\n",
    "# x_orig = get_features('../data/gpt-4/pubmed_Ans_gpt-4.original.gpt2xl.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_orig = np.zeros(x_orig.shape[0])\n",
    "\n",
    "# x_samp = get_features('../data/gpt-4/pubmed_Ans_gpt-4.sampled.gpt2.nlllogzs.fftreal.txt')\n",
    "# x_samp = get_features('../data/gpt-4/pubmed_Ans_gpt-4.sampled.gpt2xl.nlllogzs.fftreal.txt')\n",
    "x_samp = get_features('../data/gpt-4/pubmed_QA_gpt-4.sampled.gpt2xl.nlllogzs.fftnorm.circlemean.txt') # Best acc=.80\n",
    "# x_samp = get_features('../data/gpt-4/pubmed_Ans_gpt-4.sampled.gpt2xl.nlllogzs.fftnorm.circlemean.txt')\n",
    "y_samp = np.ones(x_samp.shape[0])\n",
    "\n",
    "freq_left_end = 0.0\n",
    "freq_right_end = 0.5\n",
    "x_orig = x_orig[:, int(freq_left_end/0.5 * x_orig.shape[1]): int(freq_right_end/0.5 * x_orig.shape[1])]\n",
    "x_samp = x_samp[:, int(freq_left_end/0.5 * x_samp.shape[1]): int(freq_right_end/0.5 * x_samp.shape[1])]\n",
    "\n",
    "x = np.concatenate([x_orig, x_samp], axis=0)\n",
    "y = np.concatenate([y_orig, y_samp], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (240, 500) (240,)\n",
      "test: (60, 500) (60,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print('train:', x_train.shape, y_train.shape)\n",
    "print('test:', x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.53333333 0.58333333 0.56666667 0.55       0.48333333]\n",
      "0.5433333333333333\n"
     ]
    }
   ],
   "source": [
    "model = make_pipeline(StandardScaler(),\n",
    "                      SelectKBest(k=120),\n",
    "    SVC(gamma='auto', kernel='rbf', C=1))\n",
    "\n",
    "scores = cross_val_score(model, x, y, cv=5)\n",
    "print(scores)\n",
    "print(np.mean(scores))\n",
    "\n",
    "# NLL log zscore, gpt2 => 0.70\n",
    "\n",
    "# NLL log zscore, gpt2xl => 0.713\n",
    "\n",
    "## Use circular to create features\n",
    "# NLL log zscore, gpt2xl, circle + mean => 0.803"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bin voting classifier\n",
    "def bin_cls(x, y, bin_thresholds, bin_size=0.05, start_from_bin=0):\n",
    "    \"\"\"\n",
    "    x: interpolated spectra\n",
    "    y: 0 for original (human), 1 for sampled (model)\n",
    "    bin_thresholds: thresholds for each bin\n",
    "    \"\"\"\n",
    "    assert x.shape[0] == y.shape[0]\n",
    "    assert isinstance(bin_thresholds, list)\n",
    "    max_freq = 0.5\n",
    "    tp, tn, fp, fn = 0, 0, 0, 0\n",
    "    y_predictions = []\n",
    "    for i in range(x.shape[0]):\n",
    "        x_means_bin = []\n",
    "        bin_count = int(max_freq / bin_size)\n",
    "        bin_width = x.shape[1] // bin_count\n",
    "        for j in range(bin_count):\n",
    "            x_means_bin.append(np.mean(x[i, j*bin_width: (j+1)*bin_width]))\n",
    "        # make prediction for each bin and majority vote\n",
    "        y_preds = []\n",
    "        for i, (thres_orig, thres_samp) in enumerate(bin_thresholds):\n",
    "            if i < start_from_bin:\n",
    "                continue\n",
    "            if np.abs(x_means_bin[i] - thres_orig) < np.abs(x_means_bin[i] - thres_samp):\n",
    "                y_preds.append(0)\n",
    "            else:\n",
    "                y_preds.append(1)\n",
    "        y_predictions.append(y_preds)\n",
    "        zero_count = y_preds.count(0)\n",
    "        one_count = y_preds.count(1)\n",
    "        if zero_count > one_count:\n",
    "            y_pred = 0\n",
    "        elif zero_count < one_count:\n",
    "            y_pred = 1\n",
    "        else: # tie\n",
    "            y_pred = 0 if np.random.uniform() < 0.5 else 1\n",
    "        \n",
    "        if y[i] == 0: # y[i] is ground truth: 0 for orig, 1 for samp\n",
    "            if y_pred == 0:\n",
    "                tn += 1\n",
    "            else:\n",
    "                fp += 1\n",
    "        else:\n",
    "            if y_pred == 0:\n",
    "                fn += 1\n",
    "            else:\n",
    "                tp += 1\n",
    "    return tp, tn, fp, fn, y_predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
